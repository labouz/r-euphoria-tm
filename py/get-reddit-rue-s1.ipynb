{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Getting Reddit Posts on Euphoria & Rue**\n",
    "08/08/2022\n",
    "\n",
    "*Season 1: June 16 - Aug 4, 2019*\n",
    "\n",
    "*reason*: replicate upitt qualitative paper - same sampling criteria - more recent season.  \n",
    "hope to have more relvant topics but similar topics they determined thematically  \n",
    "sampling criteria:  \n",
    "- overall r/television subr\n",
    "- time frame  \n",
    "- comments that mention 'rue' - as narrator and main character  \n",
    "\n",
    "*analysis*: \n",
    "- topic modeling season 1 v 2\n",
    "  - LDA\n",
    "    - so far: getting comments for three recent top posts - 4 topics with 100 passes, no clear topics\n",
    "    - hyperparameter tuning\n",
    "      - coherence score/perplexity ...meh\n",
    "  - transformer-based\n",
    "    - `BERTopic`\n",
    "      - embeddings: \n",
    "        - all-mpnet-base-v2\n",
    "        - all-distilroberta-v1\n",
    "        - all-MiniLM-L6-v2 - *default*\n",
    "- compute valence scores for each comment and group by topic\n",
    "  - read into mood shift of main character from season 1 to 2\n",
    "- compare S1 to S2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source api credentials from file\n",
    "file = 'api-creds.py'\n",
    "exec(open(file).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/psaw/PushshiftAPI.py:252: UserWarning: Not all PushShift shards are active. Query results may be incomplete\n",
      "  warnings.warn(shards_down_message)\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/psaw/PushshiftAPI.py:192: UserWarning: Got non 200 code 429\n",
      "  warnings.warn(\"Got non 200 code %s\" % response.status_code)\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/psaw/PushshiftAPI.py:180: UserWarning: Unable to connect to pushshift.io. Retrying after backoff.\n",
      "  warnings.warn(\"Unable to connect to pushshift.io. Retrying after backoff.\")\n"
     ]
    }
   ],
   "source": [
    "from psaw import PushshiftAPI\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# inclusive, make this the first day to collect yyyy,m,d\n",
    "after = int(datetime(2019, 6, 16).timestamp()) -1\n",
    "\n",
    "# exclusive, make this the day after the last day to collect\n",
    "before = int(datetime(2019, 8, 5).timestamp())\n",
    "\n",
    "api=PushshiftAPI()\n",
    "\n",
    "# change to search_comments to collect comments instead of submissions\n",
    "subs = api.search_submissions(after=after, before=before, q=\"rue\", limit=None)\n",
    "\n",
    "# process however you want - this loads the posts into a dataframe\n",
    "df = pd.DataFrame([sub.d_ for sub in subs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('../dat/rue_s1_submissions.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rd/p010xzd55nl_33_67s8769q00000gq/T/ipykernel_32176/3138543611.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  s1_pids_df['created_utc_real'] = pd.to_datetime(s1_pids_df['created_utc'], unit='s')\n"
     ]
    }
   ],
   "source": [
    "s1_pids_df = df[['id', 'title', 'selftext', 'url', 'author', 'score', 'created_utc', 'num_comments']]\n",
    "# convert created_utc to datetime\n",
    "s1_pids_df['created_utc_real'] = pd.to_datetime(s1_pids_df['created_utc'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for domain in self.euphoria\n",
    "s1_pids_df = s1_pids_df[s1_pids_df['url'].str.contains('https://www.reddit.com/r/euphoria/')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat comments and posts that are not None \n",
    "posts = s1_pids_df['selftext']\n",
    "# filter out the None values\n",
    "posts2 = pd.DataFrame([post for post in posts if post not in [None, '', 'None', '[deleted]', '[removed]']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the id of a post, get the comments and store in a dataframe\n",
    "\n",
    "def get_comments(submission_id):\n",
    "    \"\"\"\n",
    "    Get comments from a submission\n",
    "    \"\"\"\n",
    "    comments = []\n",
    "    submission = reddit.submission(id = submission_id)\n",
    "    submission.comments.replace_more(limit = None)\n",
    "    for comment in submission.comments.list():\n",
    "        comments.append({'body': comment.body, 'author': comment.author, 'score': comment.score, 'created_utc': comment.created_utc, 'id': comment.id})\n",
    "    return comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_comments = []\n",
    "for post_id in s1_pids_df.id:\n",
    "    s1_comments.append(get_comments(post_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the body of each comment\n",
    "import math\n",
    "def get_body(df, percent = 1):\n",
    "    body_ls = []\n",
    "    for i in range(len(df)):\n",
    "        for j in range(len(df.iloc[i])):\n",
    "            if type(df.iloc[i][j]) != type(None):\n",
    "               body_ls.append(df.iloc[i][j]['body'])\n",
    "    # adjust for percentage\n",
    "    body_ls = body_ls[:math.floor(len(body_ls) * percent)]\n",
    "    return body_ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply func to all the posts\n",
    "s1_comments_df = pd.DataFrame(s1_comments)\n",
    "s1_comment_body_df = pd.DataFrame(get_body(s1_comments_df, percent = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_comments_df = pd.concat([s1_comment_body_df, posts2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "s1_comments_df.to_pickle('../dat/s1_rue_comments.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
