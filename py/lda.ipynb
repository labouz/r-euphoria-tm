{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discovering impact of the Series 'Euphoria' through NLP\n",
    "### Analysis based on posts and comments on the `r/euphoria` subreddit  \n",
    "\n",
    "#### 3. LDA - Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "= *Every documents is probability dist of topics*\n",
    "\n",
    "*goal*: LDA learns the topic mix in each doc, then words in each topic   \n",
    "\n",
    "*how*: LDA randomly assigns topics to words (will be wrong). Then, iterativly, looks for how often the topic occus in the doc and how often the word occurs in the topic overall. Based on this infor, assign the word a new topic.\n",
    "\n",
    "`k = 2` is a good starting part for number of topics  \n",
    "\n",
    "*input*: TDM, K, num iterations  \n",
    "*output*: top words in each topic - figure out if they make sense\n",
    "\n",
    "*tools*:  \n",
    "`gensim`\n",
    "\n",
    "alternate factorization methods: \n",
    "- NMF\n",
    "- LSI\n",
    "- look at BERT TM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### all posts in the r/euphoria subreddit that match 'rue' and are between jan9 and feb 2 2022 for season 2 \n",
    "\n",
    "**1st experiment**\n",
    "N ~ 20,823 post + comments (100%)\n",
    "Some notable comments:  \n",
    "- \"I was curious, so I read the /r/opiates discussion on the episode and they agree it's accurate. There's not a single negative comment.\"\n",
    "- \"Having been the partner/girlfriend of an addict, I cannot re-watch several parts of Season 2 because they feel so real to me.\"\n",
    "- \"Absolutely spot on. I've had my struggles w Vicodin and there were points when I was dope sick, I would do anything to get those damn pills. I'm still feeling some type of a way after last night's episode. That's how accurate it was\"\n",
    "- \"Yâ€™all attach too much of your selves to the characters.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXP 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aback</th>\n",
       "      <th>abaedefabdfef</th>\n",
       "      <th>abafbfbedbada</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandoning</th>\n",
       "      <th>abandonment</th>\n",
       "      <th>abashed</th>\n",
       "      <th>abdomen</th>\n",
       "      <th>abducts</th>\n",
       "      <th>...</th>\n",
       "      <th>zoned</th>\n",
       "      <th>zongao</th>\n",
       "      <th>zoning</th>\n",
       "      <th>zora</th>\n",
       "      <th>zorbcaps</th>\n",
       "      <th>zoted</th>\n",
       "      <th>zouabi</th>\n",
       "      <th>zoya</th>\n",
       "      <th>zrue</th>\n",
       "      <th>zsuzsana</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19251</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19252</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19253</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19254</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19255</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19166 rows Ã— 23242 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aback  abaedefabdfef  abafbfbedbada  abandon  abandoned  abandoning  \\\n",
       "0          0              0              0        0          0           0   \n",
       "1          0              0              0        0          0           0   \n",
       "2          0              0              0        0          0           0   \n",
       "3          0              0              0        0          0           0   \n",
       "4          0              0              0        0          0           0   \n",
       "...      ...            ...            ...      ...        ...         ...   \n",
       "19251      0              0              0        0          0           0   \n",
       "19252      0              0              0        0          0           0   \n",
       "19253      0              0              0        0          0           0   \n",
       "19254      0              0              0        0          0           0   \n",
       "19255      0              0              0        0          0           0   \n",
       "\n",
       "       abandonment  abashed  abdomen  abducts  ...  zoned  zongao  zoning  \\\n",
       "0                0        0        0        0  ...      0       0       0   \n",
       "1                0        0        0        0  ...      0       0       0   \n",
       "2                0        0        0        0  ...      0       0       0   \n",
       "3                0        0        0        0  ...      0       0       0   \n",
       "4                0        0        0        0  ...      0       0       0   \n",
       "...            ...      ...      ...      ...  ...    ...     ...     ...   \n",
       "19251            0        0        0        0  ...      0       0       0   \n",
       "19252            0        0        0        0  ...      0       0       0   \n",
       "19253            0        0        0        0  ...      0       0       0   \n",
       "19254            0        0        0        0  ...      0       0       0   \n",
       "19255            0        0        0        0  ...      0       0       0   \n",
       "\n",
       "       zora  zorbcaps  zoted  zouabi  zoya  zrue  zsuzsana  \n",
       "0         0         0      0       0     0     0         0  \n",
       "1         0         0      0       0     0     0         0  \n",
       "2         0         0      0       0     0     0         0  \n",
       "3         0         0      0       0     0     0         0  \n",
       "4         0         0      0       0     0     0         0  \n",
       "...     ...       ...    ...     ...   ...   ...       ...  \n",
       "19251     0         0      0       0     0     0         0  \n",
       "19252     0         0      0       0     0     0         0  \n",
       "19253     0         0      0       0     0     0         0  \n",
       "19254     0         0      0       0     0     0         0  \n",
       "19255     0         0      0       0     0     0         0  \n",
       "\n",
       "[19166 rows x 23242 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bring in data\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "data = pd.read_pickle('../dat/tdm_stop.pkl')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import matutils, models\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>19245</th>\n",
       "      <th>19246</th>\n",
       "      <th>19247</th>\n",
       "      <th>19248</th>\n",
       "      <th>19250</th>\n",
       "      <th>19251</th>\n",
       "      <th>19252</th>\n",
       "      <th>19253</th>\n",
       "      <th>19254</th>\n",
       "      <th>19255</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aback</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abaedefabdfef</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abafbfbedbada</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abandon</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abandoned</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 19166 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0      1      2      3      4      5      6      7      8      \\\n",
       "aback              0      0      0      0      0      0      0      0      0   \n",
       "abaedefabdfef      0      0      0      0      0      0      0      0      0   \n",
       "abafbfbedbada      0      0      0      0      0      0      0      0      0   \n",
       "abandon            0      0      0      0      0      0      0      0      0   \n",
       "abandoned          0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "               9      ...  19245  19246  19247  19248  19250  19251  19252  \\\n",
       "aback              0  ...      0      0      0      0      0      0      0   \n",
       "abaedefabdfef      0  ...      0      0      0      0      0      0      0   \n",
       "abafbfbedbada      0  ...      0      0      0      0      0      0      0   \n",
       "abandon            0  ...      0      0      0      0      0      0      0   \n",
       "abandoned          0  ...      0      0      0      0      0      0      0   \n",
       "\n",
       "               19253  19254  19255  \n",
       "aback              0      0      0  \n",
       "abaedefabdfef      0      0      0  \n",
       "abafbfbedbada      0      0      0  \n",
       "abandon            0      0      0  \n",
       "abandoned          0      0      0  \n",
       "\n",
       "[5 rows x 19166 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdm = data.transpose()\n",
    "tdm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put tdm in gensim format\n",
    "sparse_counts = sp.csr_matrix(tdm)\n",
    "corpus = matutils.Sparse2Corpus(sparse_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a dictionary of all terms - required by gensim\n",
    "# cv contains the whole vocabulary of the corpus\n",
    "cv = pickle.load(open('../dat/cv_Stop.pkl', 'rb'))\n",
    "id2word = dict((v, k) for k, v in cv.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have corpus and id2word, now we can create the lda model\n",
    "# specify other parameters\n",
    "# more passes, more it may make sense\n",
    "lda = models.ldamodel.LdaModel(corpus=corpus, id2word=id2word, num_topics=2, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.019*\"jules\" + 0.018*\"like\" + 0.014*\"think\" + 0.010*\"ml\" + 0.009*\"season\" + 0.008*\"going\" + 0.008*\"box\" + 0.008*\"nate\" + 0.008*\"know\" + 0.008*\"really\"'),\n",
       " (1,\n",
       "  '0.007*\"people\" + 0.006*\"amp\" + 0.004*\"like\" + 0.004*\"addiction\" + 0.004*\"time\" + 0.003*\"xb\" + 0.003*\"life\" + 0.003*\"day\" + 0.003*\"wel\" + 0.003*\"know\"')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.026*\"jules\" + 0.022*\"like\" + 0.015*\"think\" + 0.012*\"people\" + 0.011*\"nate\" + 0.011*\"season\" + 0.009*\"really\" + 0.008*\"cassie\" + 0.008*\"does\" + 0.007*\"know\"'),\n",
       " (1,\n",
       "  '0.012*\"fez\" + 0.010*\"like\" + 0.009*\"going\" + 0.009*\"know\" + 0.008*\"did\" + 0.007*\"think\" + 0.007*\"time\" + 0.006*\"drugs\" + 0.005*\"episode\" + 0.005*\"got\"'),\n",
       " (2,\n",
       "  '0.024*\"ml\" + 0.019*\"box\" + 0.015*\"niche\" + 0.012*\"tester\" + 0.010*\"amp\" + 0.007*\"designer\" + 0.006*\"new\" + 0.006*\"vintage\" + 0.005*\"cap\" + 0.005*\"xb\"')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lda for 3 topics\n",
    "lda = models.ldamodel.LdaModel(corpus=corpus, id2word=id2word, num_topics=3, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.034*\"jules\" + 0.021*\"like\" + 0.017*\"think\" + 0.014*\"people\" + 0.010*\"does\" + 0.009*\"really\" + 0.009*\"elliot\" + 0.008*\"know\" + 0.008*\"feel\" + 0.007*\"relationship\"'),\n",
       " (1,\n",
       "  '0.027*\"ml\" + 0.021*\"box\" + 0.017*\"niche\" + 0.014*\"tester\" + 0.011*\"amp\" + 0.008*\"designer\" + 0.007*\"vintage\" + 0.007*\"new\" + 0.006*\"cap\" + 0.006*\"xb\"'),\n",
       " (2,\n",
       "  '0.020*\"season\" + 0.018*\"like\" + 0.013*\"nate\" + 0.011*\"cassie\" + 0.011*\"episode\" + 0.010*\"lexi\" + 0.010*\"character\" + 0.010*\"think\" + 0.008*\"characters\" + 0.008*\"maddy\"'),\n",
       " (3,\n",
       "  '0.012*\"fez\" + 0.008*\"going\" + 0.007*\"did\" + 0.007*\"time\" + 0.007*\"know\" + 0.006*\"like\" + 0.006*\"drugs\" + 0.005*\"drug\" + 0.005*\"got\" + 0.005*\"think\"')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lda for 4 topics\n",
    "lda = models.ldamodel.LdaModel(corpus=corpus, id2word=id2word, num_topics=4, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRY 2**  \n",
    "\n",
    "only nouns - `nltk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "def nouns(text):\n",
    "    is_noun = lambda pos: pos[:2] == 'NN'\n",
    "    tokenized = word_tokenize(text)\n",
    "    all_nouns = [word for (word, pos) in pos_tag(tokenized) if is_noun(pos)]\n",
    "    return ' '.join(all_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it is a turning point for the series f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i am glad we finally get a whole episode dedic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my thought exactly all i could think of while ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i honestly thought with the end of ep the seas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>same i feel like we have not really seen much ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19251</th>\n",
       "      <td>the which extremely out franchised culver in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19252</th>\n",
       "      <td>so this hapened back in late november and i on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19253</th>\n",
       "      <td>i want to use the face claim of alexis bledel ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19254</th>\n",
       "      <td>i just ordered some seed and i am wanting to k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19255</th>\n",
       "      <td>i watched the bridge episode but what wa the t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19166 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       0\n",
       "0                 it is a turning point for the series f\n",
       "1      i am glad we finally get a whole episode dedic...\n",
       "2      my thought exactly all i could think of while ...\n",
       "3      i honestly thought with the end of ep the seas...\n",
       "4      same i feel like we have not really seen much ...\n",
       "...                                                  ...\n",
       "19251  the which extremely out franchised culver in t...\n",
       "19252  so this hapened back in late november and i on...\n",
       "19253  i want to use the face claim of alexis bledel ...\n",
       "19254  i just ordered some seed and i am wanting to k...\n",
       "19255  i watched the bridge episode but what wa the t...\n",
       "\n",
       "[19166 rows x 1 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read clean data\n",
    "data_clean = pd.read_pickle('../dat/corpus.pkl')\n",
    "data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>point series f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i glad episode protagonist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i watching show shitshow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i end ep season wa space kind mediocre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>season episode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19251</th>\n",
       "      <td>culver restaurant family etc culvers culvers i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19252</th>\n",
       "      <td>november i work dimsum restaurant city folowin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19253</th>\n",
       "      <td>i face claim bledel character specificaly seas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19254</th>\n",
       "      <td>i seed i way</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19255</th>\n",
       "      <td>i bridge episode timeline jules rue i detail</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19166 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       0\n",
       "0                                         point series f\n",
       "1                             i glad episode protagonist\n",
       "2                               i watching show shitshow\n",
       "3                 i end ep season wa space kind mediocre\n",
       "4                                         season episode\n",
       "...                                                  ...\n",
       "19251  culver restaurant family etc culvers culvers i...\n",
       "19252  november i work dimsum restaurant city folowin...\n",
       "19253  i face claim bledel character specificaly seas...\n",
       "19254                                       i seed i way\n",
       "19255       i bridge episode timeline jules rue i detail\n",
       "\n",
       "[19166 rows x 1 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter so only nouns are left\n",
    "data_nouns = pd.DataFrame(data_clean[0].apply(nouns))\n",
    "data_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aback</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandonment</th>\n",
       "      <th>abdomen</th>\n",
       "      <th>abducts</th>\n",
       "      <th>abe</th>\n",
       "      <th>abey</th>\n",
       "      <th>abigail</th>\n",
       "      <th>ability</th>\n",
       "      <th>ableism</th>\n",
       "      <th>...</th>\n",
       "      <th>zombicide</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zomer</th>\n",
       "      <th>zomg</th>\n",
       "      <th>zone</th>\n",
       "      <th>zongao</th>\n",
       "      <th>zora</th>\n",
       "      <th>zorbcaps</th>\n",
       "      <th>zouabi</th>\n",
       "      <th>zoya</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19251</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19252</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19253</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19254</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19255</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19166 rows Ã— 14342 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aback  abandon  abandonment  abdomen  abducts  abe  abey  abigail  \\\n",
       "0          0        0            0        0        0    0     0        0   \n",
       "1          0        0            0        0        0    0     0        0   \n",
       "2          0        0            0        0        0    0     0        0   \n",
       "3          0        0            0        0        0    0     0        0   \n",
       "4          0        0            0        0        0    0     0        0   \n",
       "...      ...      ...          ...      ...      ...  ...   ...      ...   \n",
       "19251      0        0            0        0        0    0     0        0   \n",
       "19252      0        0            0        0        0    0     0        0   \n",
       "19253      0        0            0        0        0    0     0        0   \n",
       "19254      0        0            0        0        0    0     0        0   \n",
       "19255      0        0            0        0        0    0     0        0   \n",
       "\n",
       "       ability  ableism  ...  zombicide  zombie  zomer  zomg  zone  zongao  \\\n",
       "0            0        0  ...          0       0      0     0     0       0   \n",
       "1            0        0  ...          0       0      0     0     0       0   \n",
       "2            0        0  ...          0       0      0     0     0       0   \n",
       "3            0        0  ...          0       0      0     0     0       0   \n",
       "4            0        0  ...          0       0      0     0     0       0   \n",
       "...        ...      ...  ...        ...     ...    ...   ...   ...     ...   \n",
       "19251        0        0  ...          0       0      0     0     0       0   \n",
       "19252        0        0  ...          0       0      0     0     0       0   \n",
       "19253        0        0  ...          0       0      0     0     0       0   \n",
       "19254        0        0  ...          0       0      0     0     0       0   \n",
       "19255        0        0  ...          0       0      0     0     0       0   \n",
       "\n",
       "       zora  zorbcaps  zouabi  zoya  \n",
       "0         0         0       0     0  \n",
       "1         0         0       0     0  \n",
       "2         0         0       0     0  \n",
       "3         0         0       0     0  \n",
       "4         0         0       0     0  \n",
       "...     ...       ...     ...   ...  \n",
       "19251     0         0       0     0  \n",
       "19252     0         0       0     0  \n",
       "19253     0         0       0     0  \n",
       "19254     0         0       0     0  \n",
       "19255     0         0       0     0  \n",
       "\n",
       "[19166 rows x 14342 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create new dtm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import text\n",
    "\n",
    "# add additional stop words - HOW TO ACCOUNT FOR PEOPLE BANGING ON KEYBOARDS?!?!?!?\n",
    "add_stop_words = ['i', 'just','did', 'ab', 'amp', 'ml', 'xb','abc', 'abcb', 'abcny', 'abd', 'abdabca', 'fs', \n",
    "                  'zpqxhxhzanapjsjbf', 'zqcsrpwsge', 'zqnuhckwdqwrhkuo', 'zs', 'zshwbhethehenozxfyqg',\n",
    "                  'zsmkbrmwngzsibrntkt', 'zy', 'zwhnrmujykdxmntiub', 'afqjcnguytghbsuvixmglpwzqbg', 'ebecadcbdfcbafbdb',\n",
    "                  'abfbmltmqspf', 'abfafebfbad']\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(add_stop_words)\n",
    "\n",
    "# dtm\n",
    "cvn = CountVectorizer(stop_words=stop_words)\n",
    "data_cvn = cvn.fit_transform(data_nouns[0])\n",
    "data_dtmn = pd.DataFrame(data_cvn.toarray(), columns=cvn.get_feature_names_out())\n",
    "data_dtmn.index = data_nouns.index\n",
    "data_dtmn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create gensim corpus\n",
    "corpusn = matutils.Sparse2Corpus(sp.csr_matrix(data_dtmn.transpose()))\n",
    "# vocab\n",
    "id2wordn = dict((v, k) for k, v in cvn.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 topics\n",
    "ldan = models.ldamodel.LdaModel(corpus=corpusn, id2word=id2wordn, num_topics=2, passes=10)\n",
    "ldan.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 topics\n",
    "ldan = models.ldamodel.LdaModel(corpus=corpusn, id2word=id2wordn, num_topics=3, passes=10)\n",
    "ldan.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.030*\"box\" + 0.022*\"niche\" + 0.020*\"tester\" + 0.011*\"designer\" + 0.010*\"vintage\" + 0.009*\"amp\" + 0.008*\"cap\" + 0.006*\"chanel\" + 0.006*\"xb\" + 0.004*\"city\"'),\n",
       " (1,\n",
       "  '0.091*\"rue\" + 0.089*\"jules\" + 0.023*\"episode\" + 0.019*\"relationship\" + 0.015*\"elliot\" + 0.015*\"way\" + 0.013*\"people\" + 0.012*\"drugs\" + 0.011*\"rues\" + 0.010*\"season\"'),\n",
       " (2,\n",
       "  '0.019*\"drugs\" + 0.017*\"people\" + 0.016*\"fez\" + 0.015*\"rue\" + 0.015*\"drug\" + 0.015*\"time\" + 0.015*\"life\" + 0.009*\"way\" + 0.008*\"family\" + 0.007*\"house\"'),\n",
       " (3,\n",
       "  '0.040*\"season\" + 0.027*\"cassie\" + 0.026*\"nate\" + 0.026*\"character\" + 0.024*\"people\" + 0.022*\"characters\" + 0.015*\"maddy\" + 0.015*\"lexi\" + 0.013*\"lot\" + 0.012*\"story\"')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4 topics\n",
    "ldan = models.ldamodel.LdaModel(corpus=corpusn, id2word=id2wordn, num_topics=4, passes=10)\n",
    "ldan.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try 3 - nouns and adjectives**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nouns_adj(text):\n",
    "    is_noun_adj = lambda pos: pos[:2] == 'NN' or pos[:2] == 'JJ'\n",
    "    tokenized = word_tokenize(text)\n",
    "    nouns_adj = [word for (word, pos) in pos_tag(tokenized) if is_noun_adj(pos)]\n",
    "    return ' '.join(nouns_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>turning point series f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i glad whole episode protagonist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i watching doe show shitshow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i end ep season wa space kind mediocre real na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>same i season whole episode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19251</th>\n",
       "      <td>culver famous branched restaurant family desse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19252</th>\n",
       "      <td>late november i most i work nice chinese ameri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19253</th>\n",
       "      <td>i face claim alexis bledel character specifica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19254</th>\n",
       "      <td>i seed i best way</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19255</th>\n",
       "      <td>i bridge episode timeline jules rue i detail</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19166 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       0\n",
       "0                                 turning point series f\n",
       "1                       i glad whole episode protagonist\n",
       "2                           i watching doe show shitshow\n",
       "3      i end ep season wa space kind mediocre real na...\n",
       "4                            same i season whole episode\n",
       "...                                                  ...\n",
       "19251  culver famous branched restaurant family desse...\n",
       "19252  late november i most i work nice chinese ameri...\n",
       "19253  i face claim alexis bledel character specifica...\n",
       "19254                                  i seed i best way\n",
       "19255       i bridge episode timeline jules rue i detail\n",
       "\n",
       "[19166 rows x 1 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_nouns_adj = pd.DataFrame(data_clean[0].apply(nouns_adj))\n",
    "data_nouns_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aback</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandonment</th>\n",
       "      <th>abdomen</th>\n",
       "      <th>abducts</th>\n",
       "      <th>abe</th>\n",
       "      <th>abey</th>\n",
       "      <th>abhorent</th>\n",
       "      <th>abigail</th>\n",
       "      <th>ability</th>\n",
       "      <th>...</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zomer</th>\n",
       "      <th>zomg</th>\n",
       "      <th>zone</th>\n",
       "      <th>zongao</th>\n",
       "      <th>zora</th>\n",
       "      <th>zorbcaps</th>\n",
       "      <th>zouabi</th>\n",
       "      <th>zoya</th>\n",
       "      <th>zrue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19251</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19252</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19253</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19254</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19255</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19166 rows Ã— 18057 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aback  abandon  abandonment  abdomen  abducts  abe  abey  abhorent  \\\n",
       "0          0        0            0        0        0    0     0         0   \n",
       "1          0        0            0        0        0    0     0         0   \n",
       "2          0        0            0        0        0    0     0         0   \n",
       "3          0        0            0        0        0    0     0         0   \n",
       "4          0        0            0        0        0    0     0         0   \n",
       "...      ...      ...          ...      ...      ...  ...   ...       ...   \n",
       "19251      0        0            0        0        0    0     0         0   \n",
       "19252      0        0            0        0        0    0     0         0   \n",
       "19253      0        0            0        0        0    0     0         0   \n",
       "19254      0        0            0        0        0    0     0         0   \n",
       "19255      0        0            0        0        0    0     0         0   \n",
       "\n",
       "       abigail  ability  ...  zombie  zomer  zomg  zone  zongao  zora  \\\n",
       "0            0        0  ...       0      0     0     0       0     0   \n",
       "1            0        0  ...       0      0     0     0       0     0   \n",
       "2            0        0  ...       0      0     0     0       0     0   \n",
       "3            0        0  ...       0      0     0     0       0     0   \n",
       "4            0        0  ...       0      0     0     0       0     0   \n",
       "...        ...      ...  ...     ...    ...   ...   ...     ...   ...   \n",
       "19251        0        0  ...       0      0     0     0       0     0   \n",
       "19252        0        0  ...       0      0     0     0       0     0   \n",
       "19253        0        0  ...       0      0     0     0       0     0   \n",
       "19254        0        0  ...       0      0     0     0       0     0   \n",
       "19255        0        0  ...       0      0     0     0       0     0   \n",
       "\n",
       "       zorbcaps  zouabi  zoya  zrue  \n",
       "0             0       0     0     0  \n",
       "1             0       0     0     0  \n",
       "2             0       0     0     0  \n",
       "3             0       0     0     0  \n",
       "4             0       0     0     0  \n",
       "...         ...     ...   ...   ...  \n",
       "19251         0       0     0     0  \n",
       "19252         0       0     0     0  \n",
       "19253         0       0     0     0  \n",
       "19254         0       0     0     0  \n",
       "19255         0       0     0     0  \n",
       "\n",
       "[19166 rows x 18057 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tdm\n",
    "cvna = CountVectorizer(stop_words=stop_words, max_df=0.8)\n",
    "data_cvna = cvna.fit_transform(data_nouns_adj[0])\n",
    "data_dtmna = pd.DataFrame(data_cvna.toarray(), columns=cvna.get_feature_names_out())\n",
    "data_dtmna.index = data_nouns_adj.index\n",
    "data_dtmna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create gensim corpus\n",
    "corpusna = matutils.Sparse2Corpus(sp.csr_matrix(data_dtmna.transpose()))\n",
    "# vocab\n",
    "id2wordna = dict((v, k) for k, v in cvna.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.040*\"rue\" + 0.026*\"jules\" + 0.015*\"people\" + 0.014*\"season\" + 0.014*\"wa\" + 0.013*\"drug\" + 0.013*\"character\" + 0.012*\"episode\" + 0.011*\"thing\" + 0.011*\"nate\"'),\n",
       " (1,\n",
       "  '0.018*\"box\" + 0.013*\"niche\" + 0.012*\"tester\" + 0.008*\"edp\" + 0.007*\"designer\" + 0.007*\"new\" + 0.006*\"vintage\" + 0.006*\"di\" + 0.005*\"chanel\" + 0.005*\"cap\"')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2 topics\n",
    "ldana = models.ldamodel.LdaModel(corpus=corpusna, id2word=id2wordna, num_topics=2, passes=10)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.065*\"rue\" + 0.063*\"jules\" + 0.028*\"season\" + 0.024*\"episode\" + 0.017*\"character\" + 0.016*\"relationship\" + 0.015*\"people\" + 0.013*\"elliot\" + 0.011*\"thing\" + 0.009*\"wa\"'),\n",
       " (1,\n",
       "  '0.020*\"box\" + 0.015*\"niche\" + 0.013*\"tester\" + 0.009*\"edp\" + 0.007*\"designer\" + 0.007*\"new\" + 0.007*\"vintage\" + 0.006*\"di\" + 0.006*\"chanel\" + 0.005*\"cap\"'),\n",
       " (2,\n",
       "  '0.020*\"rue\" + 0.017*\"wa\" + 0.016*\"nate\" + 0.015*\"drug\" + 0.013*\"people\" + 0.013*\"cassie\" + 0.012*\"time\" + 0.011*\"fez\" + 0.010*\"life\" + 0.010*\"thing\"')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3 topics\n",
    "ldana = models.ldamodel.LdaModel(corpus=corpusna, id2word=id2wordna, num_topics=3, passes=10)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.023*\"box\" + 0.017*\"niche\" + 0.015*\"tester\" + 0.010*\"edp\" + 0.009*\"designer\" + 0.008*\"new\" + 0.008*\"vintage\" + 0.007*\"di\" + 0.007*\"chanel\" + 0.006*\"cap\"'),\n",
       " (1,\n",
       "  '0.084*\"rue\" + 0.063*\"jules\" + 0.016*\"relationship\" + 0.014*\"people\" + 0.014*\"episode\" + 0.014*\"elliot\" + 0.013*\"thing\" + 0.013*\"drug\" + 0.013*\"wa\" + 0.011*\"way\"'),\n",
       " (2,\n",
       "  '0.021*\"drug\" + 0.018*\"wa\" + 0.014*\"time\" + 0.014*\"rue\" + 0.011*\"fez\" + 0.011*\"life\" + 0.011*\"year\" + 0.011*\"people\" + 0.008*\"day\" + 0.007*\"high\"'),\n",
       " (3,\n",
       "  '0.034*\"character\" + 0.031*\"season\" + 0.030*\"nate\" + 0.023*\"cassie\" + 0.018*\"episode\" + 0.014*\"maddy\" + 0.014*\"people\" + 0.011*\"lexi\" + 0.010*\"scene\" + 0.009*\"story\"')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4 topics\n",
    "ldana = models.ldamodel.LdaModel(corpus=corpusna, id2word=id2wordna, num_topics=4, passes=10)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ID topics**\n",
    "\n",
    "last model makes a little more sense - 4 topics with nouns and adjectives\n",
    "\n",
    "Going to crank it up a notch with 8 topics, training with chunks of 1k docs, and 100 passes - let's see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try more topics on more cores\n",
    "# 8 topics\n",
    "import gensim\n",
    "ldna2 = gensim.models.LdaMulticore(corpus=corpusna,\n",
    "                                       id2word=id2wordna,\n",
    "                                       num_topics=8, \n",
    "                                       random_state=2022,\n",
    "                                       chunksize=1000,\n",
    "                                       passes=100,\n",
    "                                       per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 topics - more passes\n",
    "ldna2.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Possible Topics**\n",
    "from 4 topic model\n",
    "\n",
    "- topic 0: spam on selling fragrance (ugh)\n",
    "- topic 1: discussion on rue, jules, elliot interaction\n",
    "- topic 2: rue's drug usage\n",
    "- topic 3: maddy, nate, cassie in season 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 'smur2x'), (2, 'sn2vpk'), (0, 'sqhl33')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is the topic dist of the document\n",
    "\n",
    "corpus_transformed = ldana[corpusna]\n",
    "list(zip([a for [(a,b)] in corpus_transformed], data_dtmna.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "coh_model_lda = models.CoherenceModel(model=ldana, \n",
    "                                      texts=data_dtmna.columns,\n",
    "                                      coherence='c_v',\n",
    "                                      dictionary=dict_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make gensim Dictionary from the corpus\n",
    "dict_na = corpora.Dictionary([data_dtmna.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coh_lda = coh_model_lda.get_coherence()\n",
    "print('coherence score: ', coh_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coherence analysis to find optimal number of topics\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "    start : Initial num of topics\n",
    "    step : Increment between each topic number\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = models.ldamodel.LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics, passes=10)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "    return model_list, coherence_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_coherence_values(dictionary=id2wordna, corpus=corpusna, texts=data_nouns_adj.body, start=2, limit=40, step=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
