{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discovering impact of the Series 'Euphoria' through NLP\n",
    "### Analysis based on posts and comments on the `r/euphoria` subreddit  \n",
    "\n",
    "#### 3. LDA - Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "= *Every documents is probability dist of topics*\n",
    "\n",
    "*goal*: LDA learns the topic mix in each doc, then words in each topic   \n",
    "\n",
    "*how*: LDA randomly assigns topics to words (will be wrong). Then, iterativly, looks for how often the topic occus in the doc and how often the word occurs in the topic overall. Based on this infor, assign the word a new topic.\n",
    "\n",
    "`k = 2` is a good starting part for number of topics  \n",
    "\n",
    "*input*: TDM, K, num iterations  \n",
    "*output*: top words in each topic - figure out if they make sense\n",
    "\n",
    "*tools*:  \n",
    "`gensim`\n",
    "\n",
    "alternate factorization methods: \n",
    "- NMF\n",
    "- LSI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 posts in the r/euphoria subreddit  \n",
    "N ~ 1,709 comments\n",
    "1. Question: Does euphoria make you less likely to try drugs? Or are you more curious than you were before?\n",
    "2. Not enough people are talking about Elliot's response to Rue telling him about her plan to get \"free\" drugs from Laurie\n",
    "3. As an ex-opioid addict, Zendaya's withdrawal scenes are the most realistic portrayal I've ever seen before. her acting is phenomenal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aana</th>\n",
       "      <th>ab</th>\n",
       "      <th>aback</th>\n",
       "      <th>abby</th>\n",
       "      <th>abhorrence</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abroad</th>\n",
       "      <th>absolute</th>\n",
       "      <th>...</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zendaya</th>\n",
       "      <th>zendayas</th>\n",
       "      <th>zero</th>\n",
       "      <th>zoloft</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zooming</th>\n",
       "      <th>zs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>post</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>smur2x</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sn2vpk</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqhl33</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 5121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        aa  aana  ab  aback  abby  abhorrence  ability  able  abroad  \\\n",
       "post                                                                   \n",
       "smur2x   1     0   0      0     1           0        0     9       0   \n",
       "sn2vpk   2     1   1      1     0           0        2     6       0   \n",
       "sqhl33   3     0   1      0     0           1        0    14       1   \n",
       "\n",
       "        absolute  ...  zealand  zendaya  zendayas  zero  zoloft  zombie  zone  \\\n",
       "post              ...                                                           \n",
       "smur2x         4  ...        1        8         1     0       0       0     1   \n",
       "sn2vpk         0  ...        0        2         0     1       0       1     0   \n",
       "sqhl33         4  ...        0        4         0     3       1       1     1   \n",
       "\n",
       "        zoo  zooming  zs  \n",
       "post                      \n",
       "smur2x    0        1   1  \n",
       "sn2vpk    0        0   0  \n",
       "sqhl33    1        0   0  \n",
       "\n",
       "[3 rows x 5121 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bring in data\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "data = pd.read_pickle('../dat/tdm_stop.pkl')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import matutils, models\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>post</th>\n",
       "      <th>smur2x</th>\n",
       "      <th>sn2vpk</th>\n",
       "      <th>sqhl33</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aa</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aana</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aback</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abby</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "post   smur2x  sn2vpk  sqhl33\n",
       "aa          1       2       3\n",
       "aana        0       1       0\n",
       "ab          0       1       1\n",
       "aback       0       1       0\n",
       "abby        1       0       0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdm = data.transpose()\n",
    "tdm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put tdm in gensim format\n",
    "sparse_counts = sp.csr_matrix(tdm)\n",
    "corpus = matutils.Sparse2Corpus(sparse_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a dictionary of all terms - required by gensim\n",
    "# cv contains the whole vocabulary of the corpus\n",
    "cv = pickle.load(open('../dat/cv_Stop.pkl', 'rb'))\n",
    "id2word = dict((v, k) for k, v in cv.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have corpus and id2word, now we can create the lda model\n",
    "# specify other parameters\n",
    "# more passes, more it may make sense\n",
    "lda = models.ldamodel.LdaModel(corpus=corpus, id2word=id2word, num_topics=2, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.011*\"weed\" + 0.010*\"makes\" + 0.009*\"try\" + 0.007*\"opiates\" + 0.006*\"season\" + 0.006*\"watching\" + 0.006*\"euphoria\" + 0.006*\"drug\" + 0.006*\"life\" + 0.006*\"feel\"'),\n",
       " (1,\n",
       "  '0.009*\"think\" + 0.009*\"elliot\" + 0.007*\"addict\" + 0.007*\"jules\" + 0.006*\"going\" + 0.006*\"drug\" + 0.005*\"got\" + 0.004*\"said\" + 0.004*\"laurie\" + 0.004*\"good\"')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.001*\"try\" + 0.001*\"think\" + 0.000*\"makes\" + 0.000*\"weed\" + 0.000*\"drug\" + 0.000*\"addict\" + 0.000*\"opiates\" + 0.000*\"going\" + 0.000*\"season\" + 0.000*\"doing\"'),\n",
       " (1,\n",
       "  '0.012*\"weed\" + 0.011*\"makes\" + 0.010*\"try\" + 0.007*\"opiates\" + 0.007*\"season\" + 0.007*\"watching\" + 0.006*\"euphoria\" + 0.006*\"life\" + 0.006*\"drug\" + 0.006*\"feel\"'),\n",
       " (2,\n",
       "  '0.010*\"think\" + 0.009*\"elliot\" + 0.008*\"addict\" + 0.007*\"jules\" + 0.006*\"going\" + 0.006*\"drug\" + 0.005*\"got\" + 0.005*\"said\" + 0.005*\"laurie\" + 0.004*\"good\"')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lda for 3 topics\n",
    "lda = models.ldamodel.LdaModel(corpus=corpus, id2word=id2word, num_topics=3, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.001*\"weed\" + 0.001*\"try\" + 0.001*\"makes\" + 0.000*\"think\" + 0.000*\"going\" + 0.000*\"opiates\" + 0.000*\"watching\" + 0.000*\"make\" + 0.000*\"drug\" + 0.000*\"got\"'),\n",
       " (1,\n",
       "  '0.008*\"withdrawal\" + 0.006*\"addict\" + 0.006*\"yawning\" + 0.006*\"going\" + 0.005*\"episode\" + 0.004*\"feel\" + 0.004*\"clean\" + 0.004*\"withdrawals\" + 0.004*\"life\" + 0.003*\"bad\"'),\n",
       " (2,\n",
       "  '0.000*\"got\" + 0.000*\"addict\" + 0.000*\"think\" + 0.000*\"going\" + 0.000*\"feel\" + 0.000*\"makes\" + 0.000*\"life\" + 0.000*\"weed\" + 0.000*\"good\" + 0.000*\"drug\"'),\n",
       " (3,\n",
       "  '0.009*\"think\" + 0.009*\"weed\" + 0.008*\"makes\" + 0.007*\"drug\" + 0.007*\"try\" + 0.006*\"addict\" + 0.006*\"elliot\" + 0.005*\"going\" + 0.005*\"life\" + 0.005*\"got\"')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lda for 4 topics\n",
    "lda = models.ldamodel.LdaModel(corpus=corpus, id2word=id2word, num_topics=4, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRY 2**  \n",
    "\n",
    "only nouns - `nltk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "def nouns(text):\n",
    "    is_noun = lambda pos: pos[:2] == 'NN'\n",
    "    tokenized = word_tokenize(text)\n",
    "    all_nouns = [word for (word, pos) in pos_tag(tokenized) if is_noun(pos)]\n",
    "    return ' '.join(all_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>post_q</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>post</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>smur2x</th>\n",
       "      <td>first congrats and continued success on your s...</td>\n",
       "      <td>Likely to try drugs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sn2vpk</th>\n",
       "      <td>i think the difference between elliot and rue ...</td>\n",
       "      <td>Elliots response to free drugs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqhl33</th>\n",
       "      <td>i already smoke weed and do psychedelics but i...</td>\n",
       "      <td>Realistic portrayal of withdrawal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     body  \\\n",
       "post                                                        \n",
       "smur2x  first congrats and continued success on your s...   \n",
       "sn2vpk  i think the difference between elliot and rue ...   \n",
       "sqhl33  i already smoke weed and do psychedelics but i...   \n",
       "\n",
       "                                   post_q  \n",
       "post                                       \n",
       "smur2x                Likely to try drugs  \n",
       "sn2vpk     Elliots response to free drugs  \n",
       "sqhl33  Realistic portrayal of withdrawal  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read clean data\n",
    "data_clean = pd.read_pickle('../dat/corpus.pkl')\n",
    "data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>post</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>smur2x</th>\n",
       "      <td>congrats success sobriety show exaddict downsi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sn2vpk</th>\n",
       "      <td>i difference elliot rue health issues life ell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqhl33</th>\n",
       "      <td>i weed psychedelics i opiates everything i add...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     body\n",
       "post                                                     \n",
       "smur2x  congrats success sobriety show exaddict downsi...\n",
       "sn2vpk  i difference elliot rue health issues life ell...\n",
       "sqhl33  i weed psychedelics i opiates everything i add..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter so only nouns are left\n",
    "data_nouns = pd.DataFrame(data_clean.body.apply(nouns))\n",
    "data_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aana</th>\n",
       "      <th>aback</th>\n",
       "      <th>abhorrence</th>\n",
       "      <th>ability</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutes</th>\n",
       "      <th>absorption</th>\n",
       "      <th>abuse</th>\n",
       "      <th>abuser</th>\n",
       "      <th>...</th>\n",
       "      <th>yuck</th>\n",
       "      <th>yum</th>\n",
       "      <th>yup</th>\n",
       "      <th>zendaya</th>\n",
       "      <th>zendayas</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zooming</th>\n",
       "      <th>zs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>post</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>smur2x</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sn2vpk</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqhl33</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 2675 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        aa  aana  aback  abhorrence  ability  absolute  absolutes  absorption  \\\n",
       "post                                                                            \n",
       "smur2x   1     0      0           0        0         2          0           1   \n",
       "sn2vpk   0     1      1           0        2         0          1           0   \n",
       "sqhl33   1     0      0           1        0         2          0           0   \n",
       "\n",
       "        abuse  abuser  ...  yuck  yum  yup  zendaya  zendayas  zombie  zone  \\\n",
       "post                   ...                                                    \n",
       "smur2x      0       0  ...     1    1    0        6         1       0     0   \n",
       "sn2vpk      4       0  ...     0    0    0        2         0       1     0   \n",
       "sqhl33      6       1  ...     0    0    1        4         0       1     1   \n",
       "\n",
       "        zoo  zooming  zs  \n",
       "post                      \n",
       "smur2x    0        1   1  \n",
       "sn2vpk    0        0   0  \n",
       "sqhl33    1        0   0  \n",
       "\n",
       "[3 rows x 2675 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create new dtm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import text\n",
    "\n",
    "# add additional stop words\n",
    "add_stop_words = ['i', 'like','just','rue','did','really','people','way','know','use',\n",
    "                  'time','drugs','want','does','addiction']\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(add_stop_words)\n",
    "\n",
    "# dtm\n",
    "cvn = CountVectorizer(stop_words=stop_words)\n",
    "data_cvnn = cvn.fit_transform(data_nouns.body)\n",
    "data_dtmn = pd.DataFrame(data_cvn.toarray(), columns=cvn.get_feature_names_out())\n",
    "data_dtmn.index = data_nouns.index\n",
    "data_dtmn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create gensim corpus\n",
    "corpusn = matutils.Sparse2Corpus(sp.csr_matrix(data_dtmn.transpose()))\n",
    "# vocab\n",
    "id2wordn = dict((v, k) for k, v in cvn.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.001*\"drug\" + 0.001*\"life\" + 0.001*\"weed\" + 0.001*\"episode\" + 0.001*\"opiates\" + 0.001*\"thing\" + 0.001*\"season\" + 0.001*\"pain\" + 0.001*\"jules\" + 0.001*\"day\"'),\n",
       " (1,\n",
       "  '0.015*\"drug\" + 0.012*\"addict\" + 0.012*\"life\" + 0.010*\"season\" + 0.010*\"weed\" + 0.009*\"episode\" + 0.009*\"opiates\" + 0.009*\"jules\" + 0.008*\"years\" + 0.007*\"lot\"')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2 topics\n",
    "ldan = models.ldamodel.LdaModel(corpus=corpusn, id2word=id2wordn, num_topics=2, passes=10)\n",
    "ldan.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.014*\"season\" + 0.014*\"life\" + 0.014*\"weed\" + 0.013*\"drug\" + 0.013*\"opiates\" + 0.011*\"addict\" + 0.011*\"euphoria\" + 0.010*\"episode\" + 0.010*\"pain\" + 0.009*\"years\"'),\n",
       " (1,\n",
       "  '0.001*\"drug\" + 0.001*\"life\" + 0.001*\"addict\" + 0.001*\"jules\" + 0.001*\"pain\" + 0.001*\"years\" + 0.001*\"episode\" + 0.001*\"thing\" + 0.001*\"season\" + 0.001*\"elliot\"'),\n",
       " (2,\n",
       "  '0.021*\"jules\" + 0.018*\"elliot\" + 0.016*\"drug\" + 0.015*\"addict\" + 0.009*\"plan\" + 0.008*\"heroin\" + 0.008*\"rues\" + 0.008*\"thing\" + 0.007*\"life\" + 0.007*\"laurie\"')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3 topics\n",
    "ldan = models.ldamodel.LdaModel(corpus=corpusn, id2word=id2wordn, num_topics=3, passes=10)\n",
    "ldan.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.022*\"jules\" + 0.019*\"elliot\" + 0.017*\"drug\" + 0.016*\"addict\" + 0.010*\"plan\" + 0.009*\"heroin\" + 0.009*\"rues\" + 0.008*\"thing\" + 0.008*\"life\" + 0.007*\"laurie\"'),\n",
       " (1,\n",
       "  '0.002*\"elliot\" + 0.002*\"drug\" + 0.001*\"addict\" + 0.001*\"jules\" + 0.001*\"life\" + 0.001*\"heroin\" + 0.001*\"thing\" + 0.001*\"rues\" + 0.001*\"episode\" + 0.001*\"things\"'),\n",
       " (2,\n",
       "  '0.015*\"season\" + 0.014*\"life\" + 0.014*\"weed\" + 0.014*\"drug\" + 0.013*\"opiates\" + 0.011*\"addict\" + 0.011*\"euphoria\" + 0.011*\"episode\" + 0.010*\"pain\" + 0.010*\"years\"'),\n",
       " (3,\n",
       "  '0.001*\"drug\" + 0.001*\"life\" + 0.001*\"pain\" + 0.001*\"weed\" + 0.001*\"episode\" + 0.001*\"addict\" + 0.001*\"opiates\" + 0.001*\"euphoria\" + 0.001*\"season\" + 0.001*\"things\"')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4 topics\n",
    "ldan = models.ldamodel.LdaModel(corpus=corpusn, id2word=id2wordn, num_topics=4, passes=10)\n",
    "ldan.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try 3 - nouns and adjectives**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nouns_adj(text):\n",
    "    is_noun_adj = lambda pos: pos[:2] == 'NN' or pos[:2] == 'JJ'\n",
    "    tokenized = word_tokenize(text)\n",
    "    nouns_adj = [word for (word, pos) in pos_tag(tokenized) if is_noun_adj(pos)]\n",
    "    return ' '.join(nouns_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>post</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>smur2x</th>\n",
       "      <td>congrats continued success sobriety incredible...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sn2vpk</th>\n",
       "      <td>i difference elliot rue mental health issues m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqhl33</th>\n",
       "      <td>i weed psychedelics i opiates everything i add...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     body\n",
       "post                                                     \n",
       "smur2x  congrats continued success sobriety incredible...\n",
       "sn2vpk  i difference elliot rue mental health issues m...\n",
       "sqhl33  i weed psychedelics i opiates everything i add..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_nouns_adj = pd.DataFrame(data_clean.body.apply(nouns_adj))\n",
    "data_nouns_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aana</th>\n",
       "      <th>ab</th>\n",
       "      <th>aback</th>\n",
       "      <th>abby</th>\n",
       "      <th>abhorrence</th>\n",
       "      <th>ability</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutes</th>\n",
       "      <th>absorption</th>\n",
       "      <th>...</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yuck</th>\n",
       "      <th>yum</th>\n",
       "      <th>yup</th>\n",
       "      <th>zendayas</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zooming</th>\n",
       "      <th>zs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>post</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>smur2x</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sn2vpk</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqhl33</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 3135 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        aa  aana  ab  aback  abby  abhorrence  ability  absolute  absolutes  \\\n",
       "post                                                                          \n",
       "smur2x   1     0   0      0     1           0        0         4          0   \n",
       "sn2vpk   0     1   1      1     0           0        2         0          1   \n",
       "sqhl33   3     0   0      0     0           1        0         4          0   \n",
       "\n",
       "        absorption  ...  youtube  yuck  yum  yup  zendayas  zombie  zone  zoo  \\\n",
       "post                ...                                                         \n",
       "smur2x           1  ...        0     1    1    0         1       0     0    0   \n",
       "sn2vpk           0  ...        0     0    0    1         0       1     0    0   \n",
       "sqhl33           0  ...        1     0    0    1         0       1     1    1   \n",
       "\n",
       "        zooming  zs  \n",
       "post                 \n",
       "smur2x        1   1  \n",
       "sn2vpk        0   0  \n",
       "sqhl33        0   0  \n",
       "\n",
       "[3 rows x 3135 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tdm\n",
    "cvna = CountVectorizer(stop_words=stop_words, max_df=0.8)\n",
    "data_cvna = cvna.fit_transform(data_nouns_adj.body)\n",
    "data_dtmna = pd.DataFrame(data_cvna.toarray(), columns=cvna.get_feature_names_out())\n",
    "data_dtmna.index = data_nouns_adj.index\n",
    "data_dtmna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create gensim corpus\n",
    "corpusna = matutils.Sparse2Corpus(sp.csr_matrix(data_dtmna.transpose()))\n",
    "# vocab\n",
    "id2wordna = dict((v, k) for k, v in cvna.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.007*\"yawning\" + 0.005*\"realistic\" + 0.004*\"opioids\" + 0.004*\"wd\" + 0.004*\"cold\" + 0.003*\"dopamine\" + 0.002*\"portrayal\" + 0.002*\"track\" + 0.002*\"ep\" + 0.002*\"acting\"'),\n",
       " (1,\n",
       "  '0.017*\"weed\" + 0.012*\"elliot\" + 0.006*\"fun\" + 0.005*\"psychedelics\" + 0.005*\"idea\" + 0.004*\"kid\" + 0.004*\"shrooms\" + 0.004*\"addictive\" + 0.004*\"party\" + 0.004*\"interested\"')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2 topics\n",
    "ldana = models.ldamodel.LdaModel(corpus=corpusna, id2word=id2wordna, num_topics=2, passes=10)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.001*\"weed\" + 0.001*\"elliot\" + 0.000*\"psychedelics\" + 0.000*\"fun\" + 0.000*\"idea\" + 0.000*\"shrooms\" + 0.000*\"addictive\" + 0.000*\"opioids\" + 0.000*\"kid\" + 0.000*\"party\"'),\n",
       " (1,\n",
       "  '0.020*\"weed\" + 0.007*\"psychedelics\" + 0.005*\"shrooms\" + 0.005*\"fun\" + 0.005*\"opioids\" + 0.004*\"addictive\" + 0.004*\"interested\" + 0.003*\"party\" + 0.003*\"couple\" + 0.003*\"desire\"'),\n",
       " (2,\n",
       "  '0.028*\"elliot\" + 0.009*\"kid\" + 0.007*\"idea\" + 0.007*\"fez\" + 0.006*\"line\" + 0.005*\"fun\" + 0.005*\"hes\" + 0.005*\"social\" + 0.004*\"character\" + 0.004*\"moment\"')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3 topics\n",
    "ldana = models.ldamodel.LdaModel(corpus=corpusna, id2word=id2wordna, num_topics=3, passes=10)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.026*\"weed\" + 0.009*\"psychedelics\" + 0.007*\"shrooms\" + 0.006*\"fun\" + 0.006*\"addictive\" + 0.005*\"interested\" + 0.004*\"party\" + 0.004*\"opioids\" + 0.004*\"desire\" + 0.003*\"scary\"'),\n",
       " (1,\n",
       "  '0.001*\"weed\" + 0.001*\"elliot\" + 0.000*\"psychedelics\" + 0.000*\"fun\" + 0.000*\"idea\" + 0.000*\"party\" + 0.000*\"interested\" + 0.000*\"addictive\" + 0.000*\"shrooms\" + 0.000*\"opioids\"'),\n",
       " (2,\n",
       "  '0.031*\"elliot\" + 0.009*\"kid\" + 0.008*\"idea\" + 0.008*\"fez\" + 0.007*\"line\" + 0.006*\"fun\" + 0.006*\"hes\" + 0.005*\"social\" + 0.005*\"character\" + 0.004*\"moment\"'),\n",
       " (3,\n",
       "  '0.010*\"yawning\" + 0.007*\"realistic\" + 0.005*\"opioids\" + 0.005*\"cold\" + 0.005*\"wd\" + 0.004*\"dopamine\" + 0.003*\"portrayal\" + 0.003*\"track\" + 0.003*\"ep\" + 0.003*\"acting\"')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4 topics\n",
    "ldana = models.ldamodel.LdaModel(corpus=corpusna, id2word=id2wordna, num_topics=4, passes=10)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ID topics**\n",
    "\n",
    "last model makes the most sense - 4topics with nouns and adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.026*\"weed\" + 0.009*\"psychedelics\" + 0.007*\"shrooms\" + 0.006*\"fun\" + 0.006*\"addictive\" + 0.005*\"interested\" + 0.004*\"party\" + 0.004*\"opioids\" + 0.004*\"desire\" + 0.003*\"scary\"'),\n",
       " (1,\n",
       "  '0.000*\"bloodstream\" + 0.000*\"blessing\" + 0.000*\"shoot\" + 0.000*\"tough\" + 0.000*\"lie\" + 0.000*\"psychopath\" + 0.000*\"prevalent\" + 0.000*\"thread\" + 0.000*\"powerful\" + 0.000*\"bot\"'),\n",
       " (2,\n",
       "  '0.031*\"elliot\" + 0.010*\"kid\" + 0.008*\"idea\" + 0.008*\"fez\" + 0.007*\"line\" + 0.006*\"hes\" + 0.006*\"fun\" + 0.005*\"social\" + 0.005*\"character\" + 0.004*\"moment\"'),\n",
       " (3,\n",
       "  '0.010*\"yawning\" + 0.007*\"realistic\" + 0.005*\"cold\" + 0.005*\"wd\" + 0.005*\"opioids\" + 0.004*\"dopamine\" + 0.003*\"ep\" + 0.003*\"track\" + 0.003*\"portrayal\" + 0.003*\"incredible\"')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4 topics - more passes\n",
    "ldana = models.ldamodel.LdaModel(corpus=corpusna, id2word=id2wordna, num_topics=4, passes=100)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Topics**\n",
    "\n",
    "- topic 0: types of drugs, party\n",
    "- topic 1: drug actions (?)\n",
    "- topic 2: characters in the show\n",
    "- topic 3: effects of drugs (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 'smur2x'), (2, 'sn2vpk'), (0, 'sqhl33')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is the topic dist of the document\n",
    "\n",
    "corpus_transformed = ldana[corpusna]\n",
    "list(zip([a for [(a,b)] in corpus_transformed], data_dtmna.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement LDA\n",
    "def lda_model(corpus, dictionary, num_topics=10, passes=20):\n",
    "    \"\"\"\n",
    "    Create LDA model\n",
    "    \"\"\"\n",
    "    lda_model = LdaMulticore(corpus=corpus,\n",
    "                             id2word=dictionary,\n",
    "                             num_topics=num_topics,\n",
    "                             passes=passes,\n",
    "                             workers=2)\n",
    "    return lda_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
