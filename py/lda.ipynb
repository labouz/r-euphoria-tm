{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discovering impact of the Series 'Euphoria' through NLP\n",
    "### Analysis based on posts and comments on the `r/euphoria` subreddit  \n",
    "\n",
    "#### 3. LDA - Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "= *Every documents is probability dist of topics*\n",
    "\n",
    "*goal*: LDA learns the topic mix in each doc, then words in each topic   \n",
    "\n",
    "*how*: LDA randomly assigns topics to words (will be wrong). Then, iterativly, looks for how often the topic occus in the doc and how often the word occurs in the topic overall. Based on this infor, assign the word a new topic.\n",
    "\n",
    "`k = 2` is a good starting part for number of topics  \n",
    "\n",
    "*input*: TDM, K, num iterations  \n",
    "*output*: top words in each topic - figure out if they make sense\n",
    "\n",
    "*tools*:  \n",
    "`gensim`\n",
    "\n",
    "alternate factorization methods: \n",
    "- NMF\n",
    "- LSI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 posts in the r/euphoria subreddit  \n",
    "N ~ 1,709 comments\n",
    "1. Question: Does euphoria make you less likely to try drugs? Or are you more curious than you were before?\n",
    "2. Not enough people are talking about Elliot's response to Rue telling him about her plan to get \"free\" drugs from Laurie\n",
    "3. As an ex-opioid addict, Zendaya's withdrawal scenes are the most realistic portrayal I've ever seen before. her acting is phenomenal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aana</th>\n",
       "      <th>ab</th>\n",
       "      <th>aback</th>\n",
       "      <th>abby</th>\n",
       "      <th>abhorrence</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abroad</th>\n",
       "      <th>absolute</th>\n",
       "      <th>...</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zendaya</th>\n",
       "      <th>zendayas</th>\n",
       "      <th>zero</th>\n",
       "      <th>zoloft</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zooming</th>\n",
       "      <th>zs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>post</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>smur2x</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sn2vpk</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqhl33</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 5121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        aa  aana  ab  aback  abby  abhorrence  ability  able  abroad  \\\n",
       "post                                                                   \n",
       "smur2x   1     0   0      0     1           0        0     9       0   \n",
       "sn2vpk   2     1   1      1     0           0        2     6       0   \n",
       "sqhl33   3     0   1      0     0           1        0    14       1   \n",
       "\n",
       "        absolute  ...  zealand  zendaya  zendayas  zero  zoloft  zombie  zone  \\\n",
       "post              ...                                                           \n",
       "smur2x         4  ...        1        8         1     0       0       0     1   \n",
       "sn2vpk         0  ...        0        2         0     1       0       1     0   \n",
       "sqhl33         4  ...        0        4         0     3       1       1     1   \n",
       "\n",
       "        zoo  zooming  zs  \n",
       "post                      \n",
       "smur2x    0        1   1  \n",
       "sn2vpk    0        0   0  \n",
       "sqhl33    1        0   0  \n",
       "\n",
       "[3 rows x 5121 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bring in data\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "data = pd.read_pickle('../dat/tdm_stop.pkl')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import matutils, models\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>post</th>\n",
       "      <th>smur2x</th>\n",
       "      <th>sn2vpk</th>\n",
       "      <th>sqhl33</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aa</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aana</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aback</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abby</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "post   smur2x  sn2vpk  sqhl33\n",
       "aa          1       2       3\n",
       "aana        0       1       0\n",
       "ab          0       1       1\n",
       "aback       0       1       0\n",
       "abby        1       0       0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdm = data.transpose()\n",
    "tdm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put tdm in gensim format\n",
    "sparse_counts = sp.csr_matrix(tdm)\n",
    "corpus = matutils.Sparse2Corpus(sparse_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a dictionary of all terms - required by gensim\n",
    "# cv contains the whole vocabulary of the corpus\n",
    "cv = pickle.load(open('../dat/cv_Stop.pkl', 'rb'))\n",
    "id2word = dict((v, k) for k, v in cv.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have corpus and id2word, now we can create the lda model\n",
    "# specify other parameters\n",
    "# more passes, more it may make sense\n",
    "lda = models.ldamodel.LdaModel(corpus=corpus, id2word=id2word, num_topics=2, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.011*\"weed\" + 0.010*\"makes\" + 0.009*\"try\" + 0.007*\"opiates\" + 0.006*\"season\" + 0.006*\"watching\" + 0.006*\"euphoria\" + 0.006*\"drug\" + 0.006*\"life\" + 0.006*\"feel\"'),\n",
       " (1,\n",
       "  '0.009*\"think\" + 0.009*\"elliot\" + 0.007*\"addict\" + 0.007*\"jules\" + 0.006*\"going\" + 0.006*\"drug\" + 0.005*\"got\" + 0.004*\"said\" + 0.004*\"laurie\" + 0.004*\"good\"')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.001*\"try\" + 0.001*\"think\" + 0.000*\"makes\" + 0.000*\"weed\" + 0.000*\"drug\" + 0.000*\"addict\" + 0.000*\"opiates\" + 0.000*\"going\" + 0.000*\"season\" + 0.000*\"doing\"'),\n",
       " (1,\n",
       "  '0.012*\"weed\" + 0.011*\"makes\" + 0.010*\"try\" + 0.007*\"opiates\" + 0.007*\"season\" + 0.007*\"watching\" + 0.006*\"euphoria\" + 0.006*\"life\" + 0.006*\"drug\" + 0.006*\"feel\"'),\n",
       " (2,\n",
       "  '0.010*\"think\" + 0.009*\"elliot\" + 0.008*\"addict\" + 0.007*\"jules\" + 0.006*\"going\" + 0.006*\"drug\" + 0.005*\"got\" + 0.005*\"said\" + 0.005*\"laurie\" + 0.004*\"good\"')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lda for 3 topics\n",
    "lda = models.ldamodel.LdaModel(corpus=corpus, id2word=id2word, num_topics=3, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.001*\"weed\" + 0.001*\"try\" + 0.001*\"makes\" + 0.000*\"think\" + 0.000*\"going\" + 0.000*\"opiates\" + 0.000*\"watching\" + 0.000*\"make\" + 0.000*\"drug\" + 0.000*\"got\"'),\n",
       " (1,\n",
       "  '0.008*\"withdrawal\" + 0.006*\"addict\" + 0.006*\"yawning\" + 0.006*\"going\" + 0.005*\"episode\" + 0.004*\"feel\" + 0.004*\"clean\" + 0.004*\"withdrawals\" + 0.004*\"life\" + 0.003*\"bad\"'),\n",
       " (2,\n",
       "  '0.000*\"got\" + 0.000*\"addict\" + 0.000*\"think\" + 0.000*\"going\" + 0.000*\"feel\" + 0.000*\"makes\" + 0.000*\"life\" + 0.000*\"weed\" + 0.000*\"good\" + 0.000*\"drug\"'),\n",
       " (3,\n",
       "  '0.009*\"think\" + 0.009*\"weed\" + 0.008*\"makes\" + 0.007*\"drug\" + 0.007*\"try\" + 0.006*\"addict\" + 0.006*\"elliot\" + 0.005*\"going\" + 0.005*\"life\" + 0.005*\"got\"')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lda for 4 topics\n",
    "lda = models.ldamodel.LdaModel(corpus=corpus, id2word=id2word, num_topics=4, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRY 2**  \n",
    "\n",
    "only nouns - `nltk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "def nouns(text):\n",
    "    is_noun = lambda pos: pos[:2] == 'NN'\n",
    "    tokenized = word_tokenize(text)\n",
    "    all_nouns = [word for (word, pos) in pos_tag(tokenized) if is_noun(pos)]\n",
    "    return ' '.join(all_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>post_q</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>post</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>smur2x</th>\n",
       "      <td>first congrats and continued success on your s...</td>\n",
       "      <td>Likely to try drugs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sn2vpk</th>\n",
       "      <td>i think the difference between elliot and rue ...</td>\n",
       "      <td>Elliots response to free drugs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqhl33</th>\n",
       "      <td>i already smoke weed and do psychedelics but i...</td>\n",
       "      <td>Realistic portrayal of withdrawal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     body  \\\n",
       "post                                                        \n",
       "smur2x  first congrats and continued success on your s...   \n",
       "sn2vpk  i think the difference between elliot and rue ...   \n",
       "sqhl33  i already smoke weed and do psychedelics but i...   \n",
       "\n",
       "                                   post_q  \n",
       "post                                       \n",
       "smur2x                Likely to try drugs  \n",
       "sn2vpk     Elliots response to free drugs  \n",
       "sqhl33  Realistic portrayal of withdrawal  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read clean data\n",
    "data_clean = pd.read_pickle('../dat/corpus.pkl')\n",
    "data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>post</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>smur2x</th>\n",
       "      <td>congrats success sobriety show exaddict downsi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sn2vpk</th>\n",
       "      <td>i difference elliot rue health issues life ell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqhl33</th>\n",
       "      <td>i weed psychedelics i opiates everything i add...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     body\n",
       "post                                                     \n",
       "smur2x  congrats success sobriety show exaddict downsi...\n",
       "sn2vpk  i difference elliot rue health issues life ell...\n",
       "sqhl33  i weed psychedelics i opiates everything i add..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter so only nouns are left\n",
    "data_nouns = pd.DataFrame(data_clean.body.apply(nouns))\n",
    "data_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aana</th>\n",
       "      <th>aback</th>\n",
       "      <th>abhorrence</th>\n",
       "      <th>ability</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutes</th>\n",
       "      <th>absorption</th>\n",
       "      <th>abuse</th>\n",
       "      <th>abuser</th>\n",
       "      <th>...</th>\n",
       "      <th>yuck</th>\n",
       "      <th>yum</th>\n",
       "      <th>yup</th>\n",
       "      <th>zendaya</th>\n",
       "      <th>zendayas</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zooming</th>\n",
       "      <th>zs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>post</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>smur2x</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sn2vpk</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqhl33</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 2675 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        aa  aana  aback  abhorrence  ability  absolute  absolutes  absorption  \\\n",
       "post                                                                            \n",
       "smur2x   1     0      0           0        0         2          0           1   \n",
       "sn2vpk   0     1      1           0        2         0          1           0   \n",
       "sqhl33   1     0      0           1        0         2          0           0   \n",
       "\n",
       "        abuse  abuser  ...  yuck  yum  yup  zendaya  zendayas  zombie  zone  \\\n",
       "post                   ...                                                    \n",
       "smur2x      0       0  ...     1    1    0        6         1       0     0   \n",
       "sn2vpk      4       0  ...     0    0    0        2         0       1     0   \n",
       "sqhl33      6       1  ...     0    0    1        4         0       1     1   \n",
       "\n",
       "        zoo  zooming  zs  \n",
       "post                      \n",
       "smur2x    0        1   1  \n",
       "sn2vpk    0        0   0  \n",
       "sqhl33    1        0   0  \n",
       "\n",
       "[3 rows x 2675 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create new dtm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import text\n",
    "\n",
    "# add additional stop words\n",
    "add_stop_words = ['i', 'like','just','rue','did','really','people','way','know','use',\n",
    "                  'time','drugs','want','does','addiction']\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(add_stop_words)\n",
    "\n",
    "# dtm\n",
    "cvn = CountVectorizer(stop_words=stop_words)\n",
    "data_cvn = cvn.fit_transform(data_nouns.body)\n",
    "data_dtm = pd.DataFrame(data_cvn.toarray(), columns=cvn.get_feature_names_out())\n",
    "data_dtm.index = data_nouns.index\n",
    "data_dtm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement LDA\n",
    "def lda_model(corpus, dictionary, num_topics=10, passes=20):\n",
    "    \"\"\"\n",
    "    Create LDA model\n",
    "    \"\"\"\n",
    "    lda_model = LdaMulticore(corpus=corpus,\n",
    "                             id2word=dictionary,\n",
    "                             num_topics=num_topics,\n",
    "                             passes=passes,\n",
    "                             workers=2)\n",
    "    return lda_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
